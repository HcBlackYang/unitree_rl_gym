
from legged_gym.envs.base.legged_robot import LeggedRobot

from isaacgym.torch_utils import *
from isaacgym import gymtorch, gymapi, gymutil
import torch
import os
import math

from legged_gym import LEGGED_GYM_ROOT_DIR

from legged_gym.envs.kitchen.kitchen_utils import parse_lisdf

from legged_gym.utils.isaacgym_utils import get_euler_xyz as get_euler_xyz_in_tensor
from legged_gym.utils.math import wrap_to_pi
from isaacgym.torch_utils import quat_apply


class G1KitchenRobot(LeggedRobot):

    def __init__(self, cfg, sim_params, physics_engine, sim_device, headless):
        # åˆå§‹åŒ–kitchen actorså­˜å‚¨
        self.kitchen_assets = {}
        self.kitchen_poses = {}
        self.kitchen_actors_by_env = {}

        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ– - è¿™ä¼šåˆ›å»ºç¯å¢ƒå’Œæœºå™¨äºº
        super().__init__(cfg, sim_params, physics_engine, sim_device, headless)

        # é‡è¦ï¼šç¡®ä¿num_actionsä¸æœºå™¨äººè‡ªç”±åº¦ä¸€è‡´
        self.num_actions = self.num_dof
        # æ›´æ–°é…ç½®ä¸­çš„å€¼ï¼Œç¡®ä¿PPOä½¿ç”¨æ­£ç¡®çš„ç»´åº¦
        self.cfg.env.num_actions = self.num_dof

    def create_sim(self):
        """ é‡å†™create_simæ–¹æ³•ï¼Œä¿®æ”¹åŠ è½½é¡ºåº """
        sim_params = self.sim_params
        if not hasattr(sim_params, "physx"):
            sim_params.physx = gymapi.PhysXParams()

        # # å¢åŠ ç¢°æ’å†…å­˜é…ç½®
        # sim_params.physx.found_lost_aggregate_pairs_capacity = 52000000  # ç•¥å¤§äºæŠ¥é”™ä¸­çš„è¦æ±‚

        self.up_axis_idx = 2
        self.sim = self.gym.create_sim(self.sim_device_id, self.graphics_device_id, self.physics_engine, sim_params)

        self._create_ground_plane()
        self._load_kitchen_assets()  # å…ˆåŠ è½½kitchenèµ„äº§
        self._create_envs()  # ç„¶ååˆ›å»ºç¯å¢ƒï¼ˆåŒ…æ‹¬æœºå™¨äººå’Œkitchenï¼‰


    def _load_kitchen_assets(self):
        """åŠ è½½æ‰€æœ‰Kitchenèµ„äº§ï¼Œåœ¨åˆ›å»ºç¯å¢ƒä¹‹å‰"""
        print("ğŸ” å¼€å§‹åŠ è½½Kitchenèµ„äº§...")
        asset_root = "/home/blake/kitchen-worlds/assets/models/"
        lisdf_path = "/home/blake/kitchen-worlds/assets/scenes/kitchen_basics.lisdf"
        pose_data = parse_lisdf(lisdf_path)

        # åŠ è½½æ‰€æœ‰URDFèµ„äº§
        for urdf_path, data in pose_data.items():
            urdf_relative_path = os.path.relpath(urdf_path, asset_root)
            if not os.path.exists(urdf_path):
                print(f"âš ï¸ Warning: URDF æ–‡ä»¶ä¸å­˜åœ¨: {urdf_path}")
                continue

            pose = data["pose"]
            scale = data["scale"]

            asset_options = gymapi.AssetOptions()
            asset_options.fix_base_link = True
            asset_options.disable_gravity = False
            asset_options.use_mesh_materials = True
            asset_options.override_com = True
            asset_options.override_inertia = True

            # ä¿®æ”¹ç¢°æ’ç”Ÿæˆé€‰é¡¹ï¼Œé¿å…å‡¸åŒ…åˆ†è§£é”™è¯¯
            asset_options.convex_decomposition_from_submeshes = False  # ç¦ç”¨ä»å­ç½‘æ ¼åˆ›å»ºå‡¸åŒ…
            asset_options.vhacd_enabled = False  # ç¦ç”¨VHACD
            asset_options.mesh_normal_mode = gymapi.COMPUTE_PER_VERTEX
            asset_options.thickness = 0.01  # å¢åŠ åšåº¦å¯èƒ½æœ‰åŠ©äºç¨³å®šæ€§

            try:
                object_asset = self.gym.load_asset(self.sim, asset_root, urdf_relative_path, asset_options)
                if object_asset is None:
                    print(f"âŒ ERROR: æ— æ³•åŠ è½½ URDF: {urdf_relative_path}")
                    continue

                self.kitchen_assets[urdf_relative_path] = object_asset
                self.kitchen_poses[urdf_relative_path] = pose
                # å­˜å‚¨scaleä¿¡æ¯
                self.kitchen_scales = getattr(self, 'kitchen_scales', {})
                self.kitchen_scales[urdf_relative_path] = scale
                print(f"âœ… æˆåŠŸåŠ è½½: {urdf_relative_path} (Scale: {scale})")
            except Exception as e:
                print(f"âŒ åŠ è½½'{urdf_relative_path}'æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                # å¦‚æœåŠ è½½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æ›´ç®€å•çš„ç¢°æ’è®¾ç½®
                try:
                    print(f"ğŸ”„ å°è¯•ä½¿ç”¨ç®€åŒ–é€‰é¡¹é‡æ–°åŠ è½½'{urdf_relative_path}'")
                    asset_options.convex_decomposition_from_submeshes = False
                    asset_options.vhacd_enabled = False
                    asset_options.default_dof_drive_mode = gymapi.DOF_MODE_NONE
                    asset_options.use_mesh_materials = False
                    # ä½¿ç”¨éå¸¸ç®€å•çš„ç¢°æ’æ¨¡å‹
                    asset_options.create_convex_meshes = False
                    asset_options.replace_cylinder_with_capsule = True

                    object_asset = self.gym.load_asset(self.sim, asset_root, urdf_relative_path, asset_options)
                    if object_asset is not None:
                        self.kitchen_assets[urdf_relative_path] = object_asset
                        self.kitchen_poses[urdf_relative_path] = pose
                        # å­˜å‚¨scaleä¿¡æ¯
                        self.kitchen_scales = getattr(self, 'kitchen_scales', {})
                        self.kitchen_scales[urdf_relative_path] = scale
                        print(f"âœ… æˆåŠŸä½¿ç”¨ç®€åŒ–é€‰é¡¹åŠ è½½: {urdf_relative_path} (Scale: {scale})")
                except Exception as e2:
                    print(f"âŒ ç®€åŒ–åŠ è½½ä»ç„¶å¤±è´¥: {e2}")
                    continue


    def _create_envs(self):
        """é‡å†™ç¯å¢ƒåˆ›å»ºæ–¹æ³•ï¼Œåˆ›å»ºæœºå™¨äººå’Œkitchenï¼Œå¹¶å¤„ç†å‡¸åŒ…ç½‘æ ¼é—®é¢˜"""
        asset_path = self.cfg.asset.file.format(LEGGED_GYM_ROOT_DIR=LEGGED_GYM_ROOT_DIR)
        asset_root = os.path.dirname(asset_path)
        asset_file = os.path.basename(asset_path)

        asset_options = gymapi.AssetOptions()
        asset_options.default_dof_drive_mode = self.cfg.asset.default_dof_drive_mode
        asset_options.collapse_fixed_joints = self.cfg.asset.collapse_fixed_joints
        asset_options.replace_cylinder_with_capsule = self.cfg.asset.replace_cylinder_with_capsule
        asset_options.flip_visual_attachments = self.cfg.asset.flip_visual_attachments
        asset_options.fix_base_link = self.cfg.asset.fix_base_link
        asset_options.density = self.cfg.asset.density
        asset_options.angular_damping = self.cfg.asset.angular_damping
        asset_options.linear_damping = self.cfg.asset.linear_damping
        asset_options.max_angular_velocity = self.cfg.asset.max_angular_velocity
        asset_options.max_linear_velocity = self.cfg.asset.max_linear_velocity
        asset_options.armature = self.cfg.asset.armature
        asset_options.thickness = self.cfg.asset.thickness
        asset_options.disable_gravity = self.cfg.asset.disable_gravity

        robot_asset = self.gym.load_asset(self.sim, asset_root, asset_file, asset_options)
        self.num_dof = self.gym.get_asset_dof_count(robot_asset)
        self.num_bodies = self.gym.get_asset_rigid_body_count(robot_asset)

        # è®¾ç½®æœºå™¨äººåŠ¨ä½œç©ºé—´å¤§å°
        self.num_actions = self.num_dof

        dof_props_asset = self.gym.get_asset_dof_properties(robot_asset)
        rigid_shape_props_asset = self.gym.get_asset_rigid_shape_properties(robot_asset)

        # ä¿å­˜bodyå’ŒDOFåç§°
        body_names = self.gym.get_asset_rigid_body_names(robot_asset)
        self.dof_names = self.gym.get_asset_dof_names(robot_asset)
        self.num_bodies = len(body_names)
        self.num_dofs = len(self.dof_names)
        feet_names = [s for s in body_names if self.cfg.asset.foot_name in s]
        penalized_contact_names = []
        for name in self.cfg.asset.penalize_contacts_on:
            penalized_contact_names.extend([s for s in body_names if name in s])
        termination_contact_names = []
        for name in self.cfg.asset.terminate_after_contacts_on:
            termination_contact_names.extend([s for s in body_names if name in s])

        base_init_state_list = self.cfg.init_state.pos + self.cfg.init_state.rot + self.cfg.init_state.lin_vel + self.cfg.init_state.ang_vel
        self.base_init_state = to_torch(base_init_state_list, device=self.device, requires_grad=False)
        start_pose = gymapi.Transform()
        start_pose.p = gymapi.Vec3(*self.base_init_state[:3])

        self._get_env_origins()

        env_lower = gymapi.Vec3(0., 0., 0.)
        env_upper = gymapi.Vec3(0., 0., 0.)
        self.actor_handles = []
        self.envs = []

        # åˆå§‹åŒ–kitchen actorså­˜å‚¨
        self.kitchen_actors_by_env = [[] for _ in range(self.num_envs)]

        spacing_factor = 5.0  # å›ºå®šçš„ç¯å¢ƒé—´è·æ”¾å¤§å› å­

        # ä¸ºæ¯ä¸ªç¯å¢ƒåˆ›å»ºæœºå™¨äººå’ŒKitchenç»„ä»¶
        for i in range(self.num_envs):
            # åˆ›å»ºç¯å¢ƒï¼ˆå…³é—­è‡ªåŠ¨ç½‘æ ¼åˆ†å¸ƒï¼šæœ€åä¸€ä¸ªå‚æ•°è®¾ä¸º1ï¼‰
            env_handle = self.gym.create_env(self.sim, env_lower, env_upper, 1)
            # ä½¿ç”¨ç¯å¢ƒåŸç‚¹ä¹˜ä»¥ spacing_factorä½œä¸ºç¯å¢ƒåç§»ï¼ˆä¸åŠ éšæœºåç§»ï¼‰
            pos = self.env_origins[i].clone() * spacing_factor
            start_pose.p = gymapi.Vec3(*pos)

            # åˆ›å»ºæœºå™¨äºº
            rigid_shape_props = self._process_rigid_shape_props(rigid_shape_props_asset, i)
            self.gym.set_asset_rigid_shape_properties(robot_asset, rigid_shape_props)
            robot_actor = self.gym.create_actor(env_handle, robot_asset, start_pose, self.cfg.asset.name, i,
                                                self.cfg.asset.self_collisions, 0)
            dof_props = self._process_dof_props(dof_props_asset, i)
            self.gym.set_actor_dof_properties(env_handle, robot_actor, dof_props)
            body_props = self.gym.get_actor_rigid_body_properties(env_handle, robot_actor)
            body_props = self._process_rigid_body_props(body_props, i)
            self.gym.set_actor_rigid_body_properties(env_handle, robot_actor, body_props, recomputeInertia=True)

            self.envs.append(env_handle)
            self.actor_handles.append(robot_actor)

            # åŠ è½½æ‰€æœ‰Kitchenç»„ä»¶ï¼Œä¸åšåˆ¤æ–­å’Œå¼‚å¸¸æ•è·
            successful_kitchen_actors = []
            for urdf_path, asset in self.kitchen_assets.items():
                self._add_kitchen_actor(i, env_handle, urdf_path, asset, successful_kitchen_actors)

            self.kitchen_actors_by_env[i] = successful_kitchen_actors

        # è®¾ç½®feetç´¢å¼•å’Œç¢°æ’ç´¢å¼•
        self.feet_indices = torch.zeros(len(feet_names), dtype=torch.long, device=self.device, requires_grad=False)
        for i in range(len(feet_names)):
            self.feet_indices[i] = self.gym.find_actor_rigid_body_handle(self.envs[0], self.actor_handles[0],
                                                                         feet_names[i])
        self.penalised_contact_indices = torch.zeros(len(penalized_contact_names), dtype=torch.long, device=self.device,
                                                     requires_grad=False)
        for i in range(len(penalized_contact_names)):
            self.penalised_contact_indices[i] = self.gym.find_actor_rigid_body_handle(self.envs[0],
                                                                                      self.actor_handles[0],
                                                                                      penalized_contact_names[i])
        self.termination_contact_indices = torch.zeros(len(termination_contact_names), dtype=torch.long,
                                                       device=self.device, requires_grad=False)
        for i in range(len(termination_contact_names)):
            self.termination_contact_indices[i] = self.gym.find_actor_rigid_body_handle(self.envs[0],
                                                                                        self.actor_handles[0],
                                                                                        termination_contact_names[i])

        # ä¸€æ¬¡æ€§å‡†å¤‡æ¨¡æ‹Ÿ - åœ¨æ‰€æœ‰actoråˆ›å»ºå
        self.gym.prepare_sim(self.sim)
        print("âœ… æ‰€æœ‰ç¯å¢ƒå’ŒKitchenåœºæ™¯åˆ›å»ºå®Œæˆï¼")

    def _add_kitchen_actor(self, env_idx, env_handle, urdf_path, asset, successful_actors_list):
        pose = self.kitchen_poses[urdf_path]
        scale = self.kitchen_scales.get(urdf_path)

        # ç¡®ä¿ä½¿ç”¨åŸæœ‰çš„ç¯å¢ƒåŸç‚¹è®¡ç®—ï¼Œå¹¶åº”ç”¨æ”¾å¤§å› å­
        spacing_factor = 5.0  # å›ºå®šçš„ç¯å¢ƒé—´è·æ”¾å¤§å› å­
        env_origin = self.env_origins[env_idx].clone() * spacing_factor

        # æ‰“å°è°ƒè¯•ä¿¡æ¯
        print(f"ç¯å¢ƒ {env_idx}: åŸç‚¹ = {env_origin}, æ”¾å¤§å› å­ = {spacing_factor}")

        # å®šä¹‰å¨æˆ¿æ•´ä½“çš„åŸºå‡†åç§»
        kitchen_base_offset = torch.tensor([2.3, 4.7, -0.002], device=self.device)

        # è®¡ç®—ç»„ä»¶çš„ç›¸å¯¹ä½ç½®ï¼šä¿ç•™åŸæœ‰è®¡ç®—æ–¹å¼ï¼Œä½†æ·»åŠ è°ƒè¯•è¾“å‡º
        transform = gymapi.Transform()
        transform.p = gymapi.Vec3(
            float(pose.pos[0]) - kitchen_base_offset[0] + env_origin[0],
            float(pose.pos[1]) - kitchen_base_offset[1] + env_origin[1],
            float(pose.pos[2]) - kitchen_base_offset[2] + env_origin[2]
        )
        transform.r = gymapi.Quat(
            float(pose.quat_wxyz[1]),
            float(pose.quat_wxyz[2]),
            float(pose.quat_wxyz[3]),
            float(pose.quat_wxyz[0])
        )

        # æ‰“å°ç»„ä»¶æœ€ç»ˆä½ç½®
        print(f"ç¯å¢ƒ {env_idx}: ç»„ä»¶ {urdf_path} æœ€ç»ˆä½ç½® = ({transform.p.x}, {transform.p.y}, {transform.p.z})")

        # åˆ›å»ºå¨æˆ¿ç»„ä»¶actor
        kitchen_actor = self.gym.create_actor(
            env_handle,
            asset,
            transform,
            f"kitchen_{urdf_path}",
            env_idx,
            2,  # ç¢°æ’ç»„
            1  # ç¢°æ’è¿‡æ»¤å™¨
        )

        if kitchen_actor is not None and scale is not None:
            try:
                if hasattr(scale, 'tolist'):
                    scale_list = scale.tolist()
                else:
                    scale_list = scale

                if isinstance(scale_list, list) and len(scale_list) == 3:
                    self.gym.set_actor_scale(env_handle, kitchen_actor, float(scale_list[0]))
                elif isinstance(scale_list, (float, int)) or (isinstance(scale_list, list) and len(scale_list) == 1):
                    scale_value = float(scale_list[0] if isinstance(scale_list, list) else scale_list)
                    self.gym.set_actor_scale(env_handle, kitchen_actor, scale_value)
                else:
                    print(f"âš ï¸ æ— æ³•åº”ç”¨ç¼©æ”¾ {scale} åˆ° {urdf_path}ï¼Œæ ¼å¼ä¸æ”¯æŒ")
            except Exception as e:
                print(f"âš ï¸ åº”ç”¨ç¼©æ”¾æ—¶å‡ºé”™: {e}")

        if kitchen_actor is not None:
            successful_actors_list.append(kitchen_actor)
            return True
        return False


    def _init_foot(self):
        """åˆå§‹åŒ–æœºå™¨äººè„šéƒ¨çŠ¶æ€"""
        self.feet_num = len(self.feet_indices)

        rigid_body_state = self.gym.acquire_rigid_body_state_tensor(self.sim)
        self.rigid_body_states = gymtorch.wrap_tensor(rigid_body_state)
        self.rigid_body_states_view = self.rigid_body_states.view(self.num_envs, -1, 13)
        self.feet_state = self.rigid_body_states_view[:, self.feet_indices, :]
        self.feet_pos = self.feet_state[:, :, :3]
        self.feet_vel = self.feet_state[:, :, 7:10]

    def update_feet_state(self):
        """æ›´æ–°è„šéƒ¨çŠ¶æ€"""
        self.gym.refresh_rigid_body_state_tensor(self.sim)

        # ç¡®ä¿rigid_body_states_viewå·²æ­£ç¡®åˆå§‹åŒ–
        if not hasattr(self, 'rigid_body_states_view') or self.rigid_body_states_view.shape[0] != self.num_envs:
            self.rigid_body_states = gymtorch.wrap_tensor(self.gym.acquire_rigid_body_state_tensor(self.sim))
            self.rigid_body_states_view = self.rigid_body_states.view(self.num_envs, -1, 13)

        # ç¡®ä¿feet_indicesæœ‰æ•ˆ
        if hasattr(self, 'feet_indices') and len(self.feet_indices) > 0:
            self.feet_state = self.rigid_body_states_view[:, self.feet_indices, :]
            self.feet_pos = self.feet_state[:, :, :3]
            self.feet_vel = self.feet_state[:, :, 7:10]
        else:
            print("âš ï¸ è­¦å‘Š: feet_indicesæœªå®šä¹‰æˆ–ä¸ºç©º")


    def _init_buffers(self):
        # å¯¼å…¥å¿…è¦çš„å‡½æ•°
        from legged_gym.utils.isaacgym_utils import get_euler_xyz
        from isaacgym.torch_utils import get_axis_params, to_torch, quat_rotate_inverse

        # è·å–gymçŠ¶æ€å¼ é‡
        actor_root_state = self.gym.acquire_actor_root_state_tensor(self.sim)
        dof_state_tensor = self.gym.acquire_dof_state_tensor(self.sim)
        net_contact_forces = self.gym.acquire_net_contact_force_tensor(self.sim)
        self.gym.refresh_dof_state_tensor(self.sim)
        self.gym.refresh_actor_root_state_tensor(self.sim)
        self.gym.refresh_net_contact_force_tensor(self.sim)

        # åˆ›å»ºåŸºæœ¬åŒ…è£…å¼ é‡ - ä¿æŒåŸå§‹å½¢çŠ¶ï¼Œä¸é‡å¡‘
        self.root_states = gymtorch.wrap_tensor(actor_root_state)
        self.dof_state = gymtorch.wrap_tensor(dof_state_tensor)
        self.contact_forces = gymtorch.wrap_tensor(net_contact_forces).view(self.num_envs, -1, 3)

        # æ‰“å°å¼ é‡å½¢çŠ¶ä¿¡æ¯ç”¨äºè°ƒè¯•
        print(f"ğŸ“Š root_stateså½¢çŠ¶: {self.root_states.shape}")
        print(f"ğŸ“Š dof_stateå½¢çŠ¶: {self.dof_state.shape}")
        print(f"ğŸ“Š contact_forceså½¢çŠ¶: {self.contact_forces.shape}")
        print(f"ğŸ“Š dof_stateæ€»å…ƒç´ æ•°: {self.dof_state.numel()}")

        # ä¸ºæœºå™¨äººåˆ›å»ºè§†å›¾ï¼Œè€Œä¸æ˜¯ä¿®æ”¹åŸå§‹å¼ é‡
        # è®¡ç®—æ¯ä¸ªç¯å¢ƒçš„actoræ•°é‡
        actors_per_env = self.root_states.shape[0] // self.num_envs

        # æ­£ç¡®åŒºåˆ†æœºå™¨äººDOFå’Œæ€»DOF
        # æ³¨æ„ï¼šdof_stateå¯èƒ½æœ‰ä¸åŒäºé¢„æœŸçš„ç»“æ„ï¼Œéœ€è¦å°å¿ƒå¤„ç†
        dofs_per_env = self.dof_state.shape[0] // self.num_envs
        robot_dofs_per_env = self.num_dof  # æœºå™¨äººçš„DOFæ•°é‡

        print(
            f"ğŸ“Š æ¯ä¸ªç¯å¢ƒçš„actors: {actors_per_env}, æ¯ä¸ªç¯å¢ƒçš„æ€»DOF: {dofs_per_env // 2}, æœºå™¨äººDOF: {robot_dofs_per_env}")

        # åˆ›å»ºæœºå™¨äººroot statesè§†å›¾ - å‡è®¾æ¯ä¸ªç¯å¢ƒçš„ç¬¬ä¸€ä¸ªactoræ˜¯æœºå™¨äºº
        robot_indices = torch.arange(0, self.root_states.shape[0], actors_per_env, device=self.device)
        self.robot_root_states = self.root_states[robot_indices]
        print(f"ğŸ“Š æœºå™¨äººroot_stateså½¢çŠ¶: {self.robot_root_states.shape}")

        # ä»æœºå™¨äººroot statesåˆ›å»ºæœ‰ç”¨çš„è§†å›¾
        self.base_quat = self.robot_root_states[:, 3:7]
        self.base_pos = self.robot_root_states[:, 0:3]

        # åˆ›å»ºDOFçŠ¶æ€ç´¢å¼•æ˜ å°„ - å…³é”®ä¿®æ”¹ç‚¹
        # ä¸ºæ¯ä¸ªç¯å¢ƒæ‰¾å‡ºæœºå™¨äººDOFçš„ç´¢å¼•
        self.robot_dof_indices = []
        for env_idx in range(self.num_envs):
            # å‡è®¾æœºå™¨äººDOFæ˜¯æ¯ä¸ªç¯å¢ƒä¸­çš„å‰robot_dofs_per_envä¸ªDOF
            start_idx = env_idx * dofs_per_env
            self.robot_dof_indices.extend([start_idx + i for i in range(robot_dofs_per_env)])

        # è½¬æ¢ä¸ºå¼ é‡ä»¥ä¾¿æ›´é«˜æ•ˆçš„ç´¢å¼•
        self.robot_dof_indices = torch.tensor(self.robot_dof_indices, dtype=torch.long, device=self.device)

        # è®¾ç½®æ‰¹æ¬¡å¤§å° - è¿™é‡Œæˆ‘ä»¬è®¾ç½®ä¸º1ï¼Œç¡®ä¿ä¸€è‡´æ€§
        self.num_batches = 1
        # self.num_batches = getattr(self.cfg.env, 'num_batches', 1)

        # å°è¯•åˆ›å»ºDOFçŠ¶æ€è§†å›¾ - ä½¿ç”¨try-exceptä»¥é€‚åº”ä¸åŒçš„ç»“æ„
        try:
            # å°è¯•åˆ›å»ºä»¥ç¯å¢ƒä¸ºå•ä½çš„è§†å›¾
            # æ³¨æ„ï¼šæ ¹æ®é”™è¯¯ä¿¡æ¯ï¼Œæˆ‘ä»¬æ€€ç–‘DOFçŠ¶æ€å¯èƒ½æ¯ä¸ªDOFæœ‰4ä¸ªå€¼(è€Œä¸æ˜¯2ä¸ª)ï¼Œæˆ–è€…æœ‰å…¶ä»–ä¸åŒçš„ç»“æ„
            total_states_per_env = self.dof_state.shape[0] // self.num_envs

            # å°è¯•åˆ›å»ºç¯å¢ƒè§†å›¾ - æ¯ä¸ªç¯å¢ƒæœ‰total_states_per_envä¸ªçŠ¶æ€
            self.dof_state_env_view = self.dof_state.view(self.num_envs, total_states_per_env)

            # æå–æœºå™¨äººDOFçŠ¶æ€ - å‡è®¾æ¯ä¸ªç¯å¢ƒä¸­å‰robot_dofs_per_env*2ä¸ªçŠ¶æ€æ˜¯æœºå™¨äººçš„
            # åˆ›å»ºæœºå™¨äººä¸“ç”¨ç¼“å†²åŒº
            # é’ˆå¯¹DOFçŠ¶æ€å¤„ç†ï¼Œä¸ä½¿ç”¨reshapeï¼Œè€Œæ˜¯ç›´æ¥ç´¢å¼•
            self.dof_pos = torch.zeros(self.num_envs, self.num_dof, device=self.device)
            self.dof_vel = torch.zeros(self.num_envs, self.num_dof, device=self.device)

            # æ‰‹åŠ¨æ›´æ–°DOFçŠ¶æ€
            self.manual_dof_update = True

            # å°è¯•æå–æœºå™¨äººDOFçŠ¶æ€
            # å¯èƒ½çš„ç»“æ„1ï¼š[pos1, vel1, pos2, vel2, ...]
            for env_idx in range(self.num_envs):
                for dof_idx in range(robot_dofs_per_env):
                    pos_idx = dof_idx * 2  # ä½ç½®ç´¢å¼•
                    vel_idx = dof_idx * 2 + 1  # é€Ÿåº¦ç´¢å¼•

                    if pos_idx < total_states_per_env and vel_idx < total_states_per_env:
                        self.dof_pos[env_idx, dof_idx] = self.dof_state_env_view[env_idx, pos_idx]
                        self.dof_vel[env_idx, dof_idx] = self.dof_state_env_view[env_idx, vel_idx]

            # åˆ›å»ºè§†å›¾ä»¥åœ¨stepä¸­ä½¿ç”¨ - è¿™åªæ˜¯ä¸€ä¸ªå½¢å¼ä¸Šçš„è®¾ç½®ï¼Œå®é™…ä¸Šæˆ‘ä»¬å°†ä½¿ç”¨ä¸Šé¢çš„ç´¢å¼•
            self.dof_pos_view = self.dof_pos
            self.dof_vel_view = self.dof_vel

            print("âœ… æˆåŠŸåˆ›å»ºDOFçŠ¶æ€è§†å›¾å’Œç¼“å†²åŒº")
        except Exception as e:
            print(f"âš ï¸ åˆ›å»ºDOFçŠ¶æ€è§†å›¾æ—¶å‡ºé”™: {e}")
            print("ä½¿ç”¨ç›´æ¥ç´¢å¼•ä»£æ›¿è§†å›¾...")

            # å¦‚æœè§†å›¾åˆ›å»ºå¤±è´¥ï¼Œåˆ›å»ºç‹¬ç«‹çš„ç¼“å†²åŒºå¹¶è®°å½•éœ€è¦æ‰‹åŠ¨æ›´æ–°
            self.dof_pos = torch.zeros(self.num_envs, robot_dofs_per_env, device=self.device)
            self.dof_vel = torch.zeros(self.num_envs, robot_dofs_per_env, device=self.device)

            # ä¸ºstepå‡½æ•°è®¾ç½®æ ‡è®°
            self.manual_dof_update = True

            # åˆ›å»ºç©ºè§†å›¾å˜é‡
            self.dof_pos_view = self.dof_pos  # è¿™åªæ˜¯å½¢å¼ä¸Šçš„èµ‹å€¼
            self.dof_vel_view = self.dof_vel  # è¿™åªæ˜¯å½¢å¼ä¸Šçš„èµ‹å€¼

        # æ¸…æ™°åœ°å®šä¹‰è®­ç»ƒå’Œæ¨ç†æ‰€éœ€çš„åŠ¨ä½œç©ºé—´å¤§å°
        self.num_actions = robot_dofs_per_env

        # å…¶ä½™åˆå§‹åŒ–
        self.rpy = get_euler_xyz(self.base_quat)
        self.common_step_counter = 0
        self.extras = {}
        self.gravity_vec = to_torch(get_axis_params(-1., self.up_axis_idx), device=self.device).repeat(
            (self.num_envs, 1))
        self.forward_vec = to_torch([1., 0., 0.], device=self.device).repeat((self.num_envs, 1))
        self.actions = torch.zeros(self.num_envs, self.num_actions, dtype=torch.float, device=self.device)

        dofs_per_env = self.dof_state.shape[0] // self.num_envs
        self.torques = torch.zeros(self.num_envs, dofs_per_env, dtype=torch.float, device=self.device)

        self.p_gains = torch.zeros(self.num_actions, dtype=torch.float, device=self.device)
        self.d_gains = torch.zeros(self.num_actions, dtype=torch.float, device=self.device)
        self.last_actions = torch.zeros(self.num_envs, self.num_actions, dtype=torch.float, device=self.device)
        self.last_dof_vel = torch.zeros_like(self.dof_vel)
        self.last_root_vel = torch.zeros_like(self.robot_root_states[:, 7:13])
        self.commands = torch.zeros(self.num_envs, self.cfg.commands.num_commands, dtype=torch.float,
                                    device=self.device)
        self.commands_scale = torch.tensor([self.obs_scales.lin_vel, self.obs_scales.lin_vel, self.obs_scales.ang_vel],
                                           device=self.device)
        self.feet_air_time = torch.zeros(self.num_envs, self.feet_indices.shape[0], dtype=torch.float,
                                         device=self.device)
        self.last_contacts = torch.zeros(self.num_envs, len(self.feet_indices), dtype=torch.bool, device=self.device)
        self.base_lin_vel = quat_rotate_inverse(self.base_quat, self.robot_root_states[:, 7:10])
        self.base_ang_vel = quat_rotate_inverse(self.base_quat, self.robot_root_states[:, 10:13])
        self.projected_gravity = quat_rotate_inverse(self.base_quat, self.gravity_vec)

        # å…³èŠ‚ä½ç½®åç§»å’ŒPDå¢ç›Š
        self.default_dof_pos = torch.zeros(self.num_dof, dtype=torch.float, device=self.device)
        for i in range(self.num_dofs):
            name = self.dof_names[i]
            angle = self.cfg.init_state.default_joint_angles[name]
            self.default_dof_pos[i] = angle
            found = False
            for dof_name in self.cfg.control.stiffness.keys():
                if dof_name in name:
                    self.p_gains[i] = self.cfg.control.stiffness[dof_name]
                    self.d_gains[i] = self.cfg.control.damping[dof_name]
                    found = True
            if not found:
                self.p_gains[i] = 0.
                self.d_gains[i] = 0.
                if self.cfg.control.control_type in ["P", "V"]:
                    print(f"PD gain of joint {name} were not defined, setting them to zero")
        self.default_dof_pos = self.default_dof_pos.unsqueeze(0)
        self.torques = self._compute_torques(self.actions).view(self.torques.shape)

        # åˆå§‹åŒ–è„šéƒ¨çŠ¶æ€
        self.feet_num = len(self.feet_indices)

        rigid_body_state = self.gym.acquire_rigid_body_state_tensor(self.sim)
        self.rigid_body_states = gymtorch.wrap_tensor(rigid_body_state)
        self.rigid_body_states_view = self.rigid_body_states.view(self.num_envs, -1, 13)
        self.feet_state = self.rigid_body_states_view[:, self.feet_indices, :]
        self.feet_pos = self.feet_state[:, :, :3]
        self.feet_vel = self.feet_state[:, :, 7:10]

        # åˆ›å»ºç”¨äºtorquesçš„è¾…åŠ©ç´¢å¼•
        self.create_torque_indices()

        # æ‰“å°è®­ç»ƒç›¸å…³å°ºå¯¸ä¿¡æ¯ï¼Œç”¨äºè°ƒè¯•
        print(f"ğŸ”§ è®­ç»ƒåŠ¨ä½œç©ºé—´å¤§å°: {self.num_actions}")
        print(f"ğŸ”§ æœºå™¨äººDOFæ•°é‡: {self.num_dof}")
        print(f"ğŸ”§ åŠ¨ä½œå¼ é‡å½¢çŠ¶: {self.actions.shape}")
        print(f"ğŸ”§ æ¯æ‰¹æ¬¡æ ·æœ¬æ•°: {self.num_batches}")

    def create_torque_indices(self):
        """åˆ›å»ºç”¨äºæ‰­çŸ©è®¡ç®—çš„ç´¢å¼•æ˜ å°„"""
        # è®¡ç®—DOFçŠ¶æ€å¼ é‡ä¸­æ¯ä¸ªç¯å¢ƒçš„å¤§å°
        states_per_env = self.dof_state.shape[0] // self.num_envs

        # åˆ›å»ºç”¨äºæ‰­çŸ©è®¡ç®—çš„ç´¢å¼•æ˜ å°„
        self.torque_indices = []

        # å‡è®¾ç»“æ„1ï¼šäº¤æ›¿çš„ä½ç½®å’Œé€Ÿåº¦
        for env_idx in range(self.num_envs):
            for dof_idx in range(self.num_actions):
                # ç»“æ„1ï¼šä½ç½®å’Œé€Ÿåº¦äº¤æ›¿
                pos_idx = env_idx * states_per_env + dof_idx * 2
                self.torque_indices.append(pos_idx)

        # è½¬æ¢ä¸ºå¼ é‡
        self.torque_indices = torch.tensor(self.torque_indices, dtype=torch.long, device=self.device)

        # æ‰“å°è°ƒè¯•ä¿¡æ¯
        print(f"ğŸ“Š ä¸ºæ‰­çŸ©è®¡ç®—åˆ›å»ºäº† {len(self.torque_indices)} ä¸ªç´¢å¼•")
        if len(self.torque_indices) > 0:
            print(f"ğŸ“Š ç¬¬ä¸€ä¸ªç´¢å¼•: {self.torque_indices[0]}, æœ€åä¸€ä¸ªç´¢å¼•: {self.torque_indices[-1]}")


    def _reset_dofs(self, env_ids):
        """ é‡ç½®æŒ‡å®šç¯å¢ƒçš„DOFä½ç½®å’Œé€Ÿåº¦ """
        # è®¾ç½®éšæœºçš„DOFä½ç½®
        self.dof_pos[env_ids] = self.default_dof_pos * torch_rand_float(0.5, 1.5, (len(env_ids), self.num_dof),
                                                                        device=self.device)
        self.dof_vel[env_ids] = 0.

        # è·å–å®Œæ•´çš„DOFçŠ¶æ€è§†å›¾
        full_dof_state = self.dof_state.view(self.num_envs, -1, 2)

        # åªæ›´æ–°æœºå™¨äººçš„DOF
        full_dof_state[env_ids, :self.num_dof, 0] = self.dof_pos[env_ids]
        full_dof_state[env_ids, :self.num_dof, 1] = self.dof_vel[env_ids]

        # å°†ç´¢å¼•è½¬æ¢ä¸ºint32
        env_ids_int32 = env_ids.to(dtype=torch.int32)

        # è®¾ç½®DOFçŠ¶æ€
        self.gym.set_dof_state_tensor_indexed(self.sim,
                                              gymtorch.unwrap_tensor(self.dof_state),
                                              gymtorch.unwrap_tensor(env_ids_int32), len(env_ids_int32))


    def step(self, actions):
        """
        æ‰§è¡ŒåŠ¨ä½œã€æ¨¡æ‹Ÿç¯å¢ƒï¼Œå¹¶è¿”å›è§‚æµ‹ã€å¥–åŠ±ç­‰ã€‚
        å¯¹äºæå‰ç»ˆæ­¢ä½†å°šæœªè¾¾åˆ° rollout_horizon çš„ç¯å¢ƒï¼Œ
        è¿”å›ä¸Šä¸€æ¬¡æœ‰æ•ˆçš„è§‚æµ‹ï¼Œä¿è¯æ¯ä¸ª rollout çš„æ­¥æ•°ä¸€è‡´ã€‚
        """
        clip_actions = self.cfg.normalization.clip_actions
        self.actions = torch.clip(actions, -clip_actions, clip_actions).to(self.device)
        if actions.dim() > 2:
            actions = actions.reshape(-1, self.num_actions)
            if actions.shape[0] != self.num_envs:
                actions = actions[:self.num_envs]

        self.render()

        for _ in range(self.cfg.control.decimation):
            self.torques = self._compute_torques(self.actions).view(self.torques.shape)
            self.gym.set_dof_actuation_force_tensor(self.sim, gymtorch.unwrap_tensor(self.torques))
            self.gym.simulate(self.sim)
            if self.cfg.env.test:
                elapsed_time = self.gym.get_elapsed_time(self.sim)
                sim_time = self.gym.get_sim_time(self.sim)
                if sim_time - elapsed_time > 0:
                    time.sleep(sim_time - elapsed_time)
            if self.device == 'cpu':
                self.gym.fetch_results(self.sim, True)
            self.gym.refresh_dof_state_tensor(self.sim)
            self.dof_pos[:] = self.dof_pos_view[:]
            self.dof_vel[:] = self.dof_vel_view[:]

        self.post_physics_step()

        # å¦‚æœæŸç¯å¢ƒåœ¨æœ¬ step å·²ç»è§¦å‘ç»ˆæ­¢ï¼ˆreset_buf åŸæœ¬ç½® 1ï¼‰ï¼Œ
        # ä½† rollout_horizon å°šæœªåˆ°è¾¾ï¼Œåˆ™ç”¨ä¸Šä¸€æ¬¡ä¿å­˜çš„ last_obs æ›¿æ¢å½“å‰ obs
        terminated = (self.reset_buf == 1)
        if terminated.any():
            self.obs_buf[terminated] = self.last_obs[terminated]
            if self.privileged_obs_buf is not None:
                self.privileged_obs_buf[terminated] = self.last_privileged_obs[terminated]
            self.rew_buf[terminated] = 0
            # åŒæ—¶æ¸…é™¤ reset_bufï¼Œé˜²æ­¢ä¸‹æ¸¸æ··æ·†
            self.reset_buf[terminated] = 0

        clip_obs = self.cfg.normalization.clip_observations
        self.obs_buf = torch.clip(self.obs_buf, -clip_obs, clip_obs)
        if self.privileged_obs_buf is not None:
            self.privileged_obs_buf = torch.clip(self.privileged_obs_buf, -clip_obs, clip_obs)
        if self.obs_buf.dim() > 2:
            self.obs_buf = self.obs_buf.reshape(self.num_envs, -1)
        if self.privileged_obs_buf is not None and self.privileged_obs_buf.dim() > 2:
            self.privileged_obs_buf = self.privileged_obs_buf.reshape(self.num_envs, -1)
        return self.obs_buf, self.privileged_obs_buf, self.rew_buf, self.reset_buf, self.extras


    def post_physics_step(self):
        """
        æ›´æ–°çŠ¶æ€ã€è®¡ç®—å¥–åŠ±ä¸ç»ˆæ­¢ï¼Œä½†å»¶è¿Ÿ reset æ“ä½œï¼Œç¡®ä¿æ¯ä¸ª rollout çš„é•¿åº¦ä¸€è‡´ã€‚
        """
        # åˆ·æ–°çŠ¶æ€å¼ é‡
        self.gym.refresh_actor_root_state_tensor(self.sim)
        self.gym.refresh_net_contact_force_tensor(self.sim)

        # æ›´æ–°æ­¥æ•°è®¡æ•°å™¨
        self.episode_length_buf += 1
        self.common_step_counter += 1

        # æå–æ¯ä¸ªç¯å¢ƒä¸­æœºå™¨äººçš„çŠ¶æ€ï¼ˆå‡è®¾æ¯ä¸ªç¯å¢ƒç¬¬ä¸€ä¸ª actor æ˜¯æœºå™¨äººï¼‰
        actors_per_env = self.root_states.shape[0] // self.num_envs
        robot_indices = torch.arange(0, self.root_states.shape[0], actors_per_env, device=self.device)
        self.robot_root_states = self.root_states[robot_indices]

        # æ›´æ–°æœºå™¨äººçŠ¶æ€ï¼Œåªé’ˆå¯¹æœºå™¨äººè€Œéå…¨éƒ¨ actor
        self.base_pos[:] = self.robot_root_states[:, 0:3]
        self.base_quat[:] = self.robot_root_states[:, 3:7]
        self.rpy[:] = get_euler_xyz_in_tensor(self.base_quat[:])
        self.base_lin_vel[:] = quat_rotate_inverse(self.base_quat, self.robot_root_states[:, 7:10])
        self.base_ang_vel[:] = quat_rotate_inverse(self.base_quat, self.robot_root_states[:, 10:13])
        self.projected_gravity[:] = quat_rotate_inverse(self.base_quat, self.gravity_vec)

        # å›è°ƒæ‰§è¡Œï¼Œæ¯”å¦‚é‡‡æ ·æŒ‡ä»¤ç­‰
        self._post_physics_step_callback()

        # æ£€æŸ¥ç»ˆæ­¢æ¡ä»¶ï¼ˆåŸºäºæ¥è§¦åŠ›ã€å€¾æ–œè§’åº¦ã€æ—¶é—´è¶…é™ç­‰ï¼‰
        self.check_termination()
        # è®¡ç®—å¥–åŠ±
        self.compute_reward()

        # ä¿å­˜å½“å‰è§‚æµ‹ä½œä¸ºæœ€åæœ‰æ•ˆè§‚æµ‹ï¼ˆç”¨äºåç»­é‚£äº›æå‰ç»ˆæ­¢çš„ç¯å¢ƒï¼‰
        # å‡è®¾ compute_observations() å·²ç»æ›´æ–°äº† self.obs_buf å’Œ self.privileged_obs_buf
        self.last_obs = self.obs_buf.clone()
        if self.privileged_obs_buf is not None:
            self.last_privileged_obs = self.privileged_obs_buf.clone()

        # å»¶è¿Ÿ resetï¼šåªæœ‰å½“æ‰€æœ‰ç¯å¢ƒå‡è¾¾åˆ° rollout_horizonï¼ˆæ¯”å¦‚ 24 æ­¥ï¼‰æ—¶ï¼Œæ‰è°ƒç”¨ reset_idx
        if torch.min(self.episode_length_buf) >= self.cfg.env.rollout_horizon:
            env_ids = torch.arange(self.num_envs, device=self.device)
            self.reset_idx(env_ids)
            self.episode_length_buf.fill_(0)
        else:
            # å¯¹äºæå‰è§¦å‘ç»ˆæ­¢çš„ç¯å¢ƒï¼Œä¸ç«‹å³ resetï¼Œè€Œæ˜¯ï¼š
            terminated = (self.reset_buf == 1)
            if terminated.any():
                # å°†å¥–åŠ±ç½® 0ï¼ˆæˆ–ç»ˆæ­¢å¥–åŠ±ï¼‰ï¼Œå¹¶æ¸…é™¤ reset æ ‡è®°ï¼Œç¡®ä¿åç»­ step è¿”å› last_obs
                self.rew_buf[terminated] = 0
                self.reset_buf[terminated] = 0

        if self.cfg.domain_rand.push_robots:
            self._push_robots()

        # è®¡ç®—æœ€ç»ˆè§‚æµ‹ï¼šå¯¹äºé‚£äº›æå‰ç»ˆæ­¢çš„ç¯å¢ƒï¼Œä»ç„¶è¿”å›ä¸Šä¸€æ¬¡æœ‰æ•ˆçš„è§‚æµ‹
        self.compute_observations()

        # ä¿å­˜æœ¬æ¬¡ step çš„çŠ¶æ€ä¾›ä¸‹æ¬¡ä½¿ç”¨
        self.last_actions[:] = self.actions[:]
        self.last_dof_vel[:] = self.dof_vel[:]
        self.last_root_vel[:] = self.robot_root_states[:, 7:13]



    def _get_noise_scale_vec(self, cfg):
        """è®¾ç½®ç”¨äºç¼©æ”¾å™ªå£°çš„å‘é‡"""
        noise_vec = torch.zeros_like(self.obs_buf[0])
        self.add_noise = self.cfg.noise.add_noise
        noise_scales = self.cfg.noise.noise_scales
        noise_level = self.cfg.noise.noise_level

        # è®¾ç½®å™ªå£°æ¯”ä¾‹ï¼ˆä¸è§‚å¯Ÿç©ºé—´ç»“æ„åŒ¹é…ï¼‰
        noise_vec[:3] = noise_scales.ang_vel * noise_level * self.obs_scales.ang_vel
        noise_vec[3:6] = noise_scales.gravity * noise_level
        noise_vec[6:9] = 0.  # commands
        noise_vec[9:9 + self.num_actions] = noise_scales.dof_pos * noise_level * self.obs_scales.dof_pos
        noise_vec[
        9 + self.num_actions:9 + 2 * self.num_actions] = noise_scales.dof_vel * noise_level * self.obs_scales.dof_vel
        noise_vec[9 + 2 * self.num_actions:9 + 3 * self.num_actions] = 0.  # previous actions
        noise_vec[9 + 3 * self.num_actions:9 + 3 * self.num_actions + 2] = 0.  # sin/cos phase

        return noise_vec

    def compute_observations(self):
        """è®¡ç®—è§‚å¯Ÿ"""
        # ç¡®ä¿add_noiseè¢«åˆå§‹åŒ–
        if not hasattr(self, 'add_noise'):
            self.add_noise = self.cfg.noise.add_noise if hasattr(self.cfg.noise, 'add_noise') else False

        # å¦‚æœè¿˜æ²¡æœ‰åˆå§‹åŒ–noise_scale_vec
        if not hasattr(self, 'noise_scale_vec') or self.noise_scale_vec is None:
            self.noise_scale_vec = self._get_noise_scale_vec(self.cfg)

        # è®¡ç®—sinå’Œcosçš„ç›¸ä½
        sin_phase = torch.sin(2 * np.pi * self.phase).unsqueeze(1)
        cos_phase = torch.cos(2 * np.pi * self.phase).unsqueeze(1)

        # æ„å»ºè§‚å¯Ÿå‘é‡ - ç¡®ä¿åªæœ‰2D [num_envs, obs_dim]
        self.obs_buf = torch.cat((self.base_ang_vel * self.obs_scales.ang_vel,
                                  self.projected_gravity,
                                  self.commands[:, :3] * self.commands_scale,
                                  (self.dof_pos - self.default_dof_pos) * self.obs_scales.dof_pos,
                                  self.dof_vel * self.obs_scales.dof_vel,
                                  self.actions,
                                  sin_phase,
                                  cos_phase
                                  ), dim=-1)

        # æ„å»ºç‰¹æƒè§‚å¯Ÿå‘é‡ - ç¡®ä¿åªæœ‰2D
        self.privileged_obs_buf = torch.cat((self.base_lin_vel * self.obs_scales.lin_vel,
                                             self.base_ang_vel * self.obs_scales.ang_vel,
                                             self.projected_gravity,
                                             self.commands[:, :3] * self.commands_scale,
                                             (self.dof_pos - self.default_dof_pos) * self.obs_scales.dof_pos,
                                             self.dof_vel * self.obs_scales.dof_vel,
                                             self.actions,
                                             sin_phase,
                                             cos_phase
                                             ), dim=-1)

        # å¦‚æœéœ€è¦ï¼Œæ·»åŠ å™ªå£°
        if self.add_noise:
            self.obs_buf += (2 * torch.rand_like(self.obs_buf) - 1) * self.noise_scale_vec

        # ç¡®ä¿è§‚å¯Ÿæ˜¯2Då¼ é‡ [num_envs, obs_dim]
        if self.obs_buf.dim() > 2:
            print(f"è­¦å‘Š: è§‚å¯Ÿå½¢çŠ¶ä¸º {self.obs_buf.shape}, å‹ç¼©ä¸º2D")
            self.obs_buf = self.obs_buf.reshape(self.num_envs, -1)

        if self.privileged_obs_buf is not None and self.privileged_obs_buf.dim() > 2:
            self.privileged_obs_buf = self.privileged_obs_buf.reshape(self.num_envs, -1)

    def _push_robots(self):
        """éšæœºæ¨åŠ¨æœºå™¨äººã€‚é€šè¿‡è®¾ç½®éšæœºåŒ–çš„åŸºç¡€é€Ÿåº¦æ¥æ¨¡æ‹Ÿå†²é‡ã€‚"""
        env_ids = torch.arange(self.num_envs, device=self.device)
        push_env_ids = env_ids[self.episode_length_buf[env_ids] % int(self.cfg.domain_rand.push_interval) == 0]
        if len(push_env_ids) == 0:
            return

        # è®¡ç®—æ¯ä¸ªç¯å¢ƒçš„actoræ•°é‡
        actors_per_env = self.root_states.shape[0] // self.num_envs

        # æœ€å¤§æ¨åŠ¨é€Ÿåº¦
        max_vel = self.cfg.domain_rand.max_push_vel_xy

        # ä¸ºæ¨åŠ¨çš„ç¯å¢ƒç”Ÿæˆéšæœºé€Ÿåº¦
        random_vel = torch_rand_float(-max_vel, max_vel, (len(push_env_ids), 2), device=self.device)

        # è®¡ç®—æœºå™¨äººåœ¨root_statesä¸­çš„ç´¢å¼•
        robot_indices = torch.arange(0, self.root_states.shape[0], actors_per_env, device=self.device)
        push_robot_indices = robot_indices[push_env_ids]

        # è®¾ç½®æœºå™¨äººçš„çº¿æ€§é€Ÿåº¦ (x/y)
        self.root_states[push_robot_indices, 7:9] = random_vel

        # è½¬æ¢ä¸ºint32ç”¨äºç´¢å¼•
        push_robot_indices_int32 = push_robot_indices.to(dtype=torch.int32)

        # æ›´æ–°root state
        self.gym.set_actor_root_state_tensor_indexed(self.sim,
                                                     gymtorch.unwrap_tensor(self.root_states),
                                                     gymtorch.unwrap_tensor(push_robot_indices_int32),
                                                     len(push_robot_indices_int32))

    def _post_physics_step_callback(self):
        """åœ¨è®¡ç®—ç»ˆæ­¢æ¡ä»¶ã€å¥–åŠ±å’Œè§‚å¯Ÿä¹‹å‰è°ƒç”¨çš„å›è°ƒ"""
        # é¦–å…ˆè°ƒç”¨çˆ¶ç±»æ–¹æ³•ï¼ˆå¦‚æœæœ‰ï¼‰
        super()._post_physics_step_callback()

        # æ›´æ–°è„šéƒ¨çŠ¶æ€
        self.update_feet_state()

        # è®¡ç®—è…¿éƒ¨ç›¸ä½ - è¿™æ˜¯æˆ‘ä»¬ç¼ºå°‘çš„å±æ€§
        period = 0.8
        offset = 0.5
        self.phase = (self.episode_length_buf * self.dt) % period / period
        self.phase_left = self.phase
        self.phase_right = (self.phase + offset) % 1
        self.leg_phase = torch.cat([self.phase_left.unsqueeze(1), self.phase_right.unsqueeze(1)], dim=-1)

        # å…¶ä»–å¿…è¦çš„è®¡ç®—...

        # ç¯å¢ƒids
        env_ids = (self.episode_length_buf % int(self.cfg.commands.resampling_time / self.dt) == 0).nonzero(
            as_tuple=False).flatten()
        self._resample_commands(env_ids)
        if self.cfg.commands.heading_command:
            forward = quat_apply(self.base_quat, self.forward_vec)
            heading = torch.atan2(forward[:, 1], forward[:, 0])
            self.commands[:, 2] = torch.clip(0.5 * wrap_to_pi(self.commands[:, 3] - heading), -1., 1.)


    def _compute_torques(self, actions):
        actions_scaled = actions * self.cfg.control.action_scale
        control_type = self.cfg.control.control_type

        if control_type == "P":
            # ä½¿ç”¨ self.dof_pos å’Œ self.dof_velï¼ˆæœºå™¨äººçš„çŠ¶æ€ï¼‰ï¼Œself.default_dof_pos çš„ shape ä¸º [1, num_dof]
            robot_torques = self.p_gains * (actions_scaled + self.default_dof_pos - self.dof_pos) \
                            - self.d_gains * self.dof_vel
        elif control_type == "V":
            robot_torques = self.p_gains * (actions_scaled - self.dof_vel) \
                            - self.d_gains * ((self.dof_vel - self.last_dof_vel) / self.sim_params.dt)
        elif control_type == "T":
            robot_torques = actions_scaled
        else:
            raise NameError(f"æœªçŸ¥æ§åˆ¶å™¨ç±»å‹: {control_type}")

        robot_torques = torch.clip(robot_torques, -self.torque_limits, self.torque_limits)

        # åˆ›å»ºä¸€ä¸ªä¸€ç»´å¼ é‡ï¼Œå…¶å…ƒç´ æ•°ä¸å…¨å±€ DOF æ•°ï¼ˆç¬¬ä¸€ç»´ï¼‰ä¸€è‡´ï¼Œå³ 960
        full_torques = torch.zeros(self.dof_state.shape[0], device=self.device)

        # å°† robot_torques å±•å¹³æˆ1Då‘é‡
        flat_robot_torques = robot_torques.reshape(-1)

        # å°†è®¡ç®—å¾—åˆ°çš„æœºå™¨äººæ‰­çŸ©å¡«å…¥å…¨å±€æ‰­çŸ©å¼ é‡ä¸­ï¼Œç´¢å¼•ç”± self.robot_dof_indices ç»™å‡º
        full_torques.index_copy_(0, self.robot_dof_indices, flat_robot_torques)

        return full_torques

    def _reward_base_height(self):
        """åŸºç¡€é«˜åº¦å¥–åŠ±"""
        # ç¡®ä¿åªä½¿ç”¨æœºå™¨äººçš„é«˜åº¦
        base_height = self.robot_root_states[:, 2]  # ä½¿ç”¨æœºå™¨äººçš„root_states
        return torch.square(base_height - self.cfg.rewards.base_height_target)

    def _reward_contact(self):
        """æ¥è§¦å¥–åŠ±"""
        res = torch.zeros(self.num_envs, dtype=torch.float, device=self.device)
        for i in range(self.feet_num):
            is_stance = self.leg_phase[:, i] < 0.55
            contact = self.contact_forces[:, self.feet_indices[i], 2] > 1
            res += ~(contact ^ is_stance)
        return res

    def _reward_feet_swing_height(self):
        """è„šéƒ¨æ‘†åŠ¨é«˜åº¦å¥–åŠ±"""
        contact = torch.norm(self.contact_forces[:, self.feet_indices, :3], dim=2) > 1.
        pos_error = torch.square(self.feet_pos[:, :, 2] - 0.08) * ~contact
        return torch.sum(pos_error, dim=(1))

    def _reward_alive(self):
        """å­˜æ´»å¥–åŠ±"""
        return torch.ones(self.num_envs, device=self.device)

    def _reward_contact_no_vel(self):
        """æ— é€Ÿåº¦æ¥è§¦æƒ©ç½š"""
        contact = torch.norm(self.contact_forces[:, self.feet_indices, :3], dim=2) > 1.
        contact_feet_vel = self.feet_vel * contact.unsqueeze(-1)
        penalize = torch.square(contact_feet_vel[:, :, :3])
        return torch.sum(penalize, dim=(1, 2))

    # def _reward_hip_pos(self):
    #     """é«‹å…³èŠ‚ä½ç½®å¥–åŠ±"""
    #     return torch.sum(torch.square(self.dof_pos[:, [1, 2, 7, 8]]), dim=1)

    def _reward_hip_pos(self):
        """é«‹å…³èŠ‚ä½ç½®å¥–åŠ±"""
        idxs = [self.dof_names.index(n) for n in [
            'left_hip_roll_joint', 'left_hip_pitch_joint',
            'right_hip_roll_joint', 'right_hip_pitch_joint'
        ]]
        return torch.sum(torch.square(self.dof_pos[:, idxs]), dim=1)

    def compute_reward(self):
        """è®¡ç®—å¥–åŠ±ï¼Œå¤„ç†å½¢çŠ¶ä¸åŒ¹é…é—®é¢˜"""
        # åˆå§‹åŒ–å¥–åŠ±ä¸ºé›¶
        self.rew_buf = torch.zeros(self.num_envs, device=self.device)

        # è°ƒç”¨æ¯ä¸ªéé›¶æ¯”ä¾‹çš„å¥–åŠ±å‡½æ•°
        for i in range(len(self.reward_functions)):
            name = self.reward_names[i]
            try:
                rew = self.reward_functions[i]() * self.reward_scales[name]

                # ç¡®ä¿å¥–åŠ±å¼ é‡å½¢çŠ¶æ­£ç¡®
                if rew.shape[0] != self.num_envs:
                    print(f"âš ï¸ å¥–åŠ±'{name}'çš„å½¢çŠ¶({rew.shape})ä¸ç¯å¢ƒæ•°é‡({self.num_envs})ä¸åŒ¹é…ï¼Œå°è¯•é‡å¡‘...")
                    # å¦‚æœå¥–åŠ±ä¸root_statesçš„æ•°é‡åŒ¹é…ï¼Œåˆ™éœ€è¦æå–æœºå™¨äººå¯¹åº”çš„å¥–åŠ±
                    if rew.shape[0] == self.root_states.shape[0]:
                        actors_per_env = self.root_states.shape[0] // self.num_envs
                        robot_indices = torch.arange(0, self.root_states.shape[0], actors_per_env, device=self.device)
                        rew = rew[robot_indices]

                self.rew_buf += rew
                self.episode_sums[name] += rew

            except Exception as e:
                print(f"âŒ è®¡ç®—å¥–åŠ±'{name}'æ—¶å‡ºé”™: {e}")
                # å‡ºé”™æ—¶ä½¿ç”¨é›¶å¥–åŠ±
                continue

        # å¦‚æœåªéœ€è¦æ­£å¥–åŠ±
        if self.cfg.rewards.only_positive_rewards:
            self.rew_buf[:] = torch.clip(self.rew_buf[:], min=0.)

        # æ·»åŠ ç»ˆæ­¢å¥–åŠ±
        if "termination" in self.reward_scales:
            try:
                rew = self._reward_termination() * self.reward_scales["termination"]
                self.rew_buf += rew
                self.episode_sums["termination"] += rew
            except Exception as e:
                print(f"âŒ è®¡ç®—ç»ˆæ­¢å¥–åŠ±æ—¶å‡ºé”™: {e}")